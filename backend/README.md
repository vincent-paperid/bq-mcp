## âš™ï¸ Project Structure
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI app initialization
â”‚   â”œâ”€â”€ config.py                  # Settings & environment variables
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py            # ChatRequest
â”‚   â”‚   â”œâ”€â”€ responses.py           # ChatResponse, HealthResponse
â”‚   â”‚   â””â”€â”€ state.py               # LangGraph State
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dependencies.py        # FastAPI dependency injection
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ health.py          # GET /health
â”‚   â”‚       â””â”€â”€ chat.py            # POST /api/chat
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mcp_service.py         # MCP client management
â”‚   â”‚   â”œâ”€â”€ agent_service.py       # LangGraph agent logic
â”‚   â”‚   â””â”€â”€ tool_wrapper.py        # Tool wrapping utilities
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ lifespan.py            # App lifecycle management
â”œâ”€â”€ main.py                        # Entry point
â””â”€â”€ pyproject.toml
```

## â˜ï¸ API Endpoints
- `GET /health` - Health check showing MCP server connection status
- `POST /api/chat` - Main endpoint that accepts prompts and returns LLM responses

Request and response example for `/api/chat` endpoint:
```
// Request
{"prompt": "Get all BigQuery datasets"}

// Response
{
  "response": "Here are your BigQuery datasets...",
  "tool_calls_made": 2
}
```

## ğŸš€ How to Run
```
python backend/main.py
```
Running the script here will start the server on `http://0.0.0.0:8000` with hot-reload enabled.